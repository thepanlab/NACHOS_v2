#!/bin/bash

#SBATCH --partition=disc_dual_a100
#SBATCH --exclusive
#SBATCH --nodes=2
#SBATCH --ntasks=5
#SBATCH --cpus-per-task=1
#SBATCH --gpus-per-node=2
#SBATCH --output=%x_%J_stdout.txt
#SBATCH --error=%x_%J_stderr.txt
#SBATCH --mem=40G
#SBATCH --time=4:00:00
#SBATCH --job-name=mpi_inner
#SBATCH --mail-user=pcallec@ou.edu
#SBATCH --mail-type=ALL
#SBATCH --chdir=/work/omicsbio/paulcalle/medical-imaging-framework/scripts
#################################################

mpirun -n 5 python3 -m training.training_multiprocessing.loop_inner.multiprocessed_training_inner_loop --file /work/omicsbio/paulcalle/medical-imaging-framework/scripts/training/training_config_files/loop_inner/config_inner_InceptionV3_modified_mpi.json